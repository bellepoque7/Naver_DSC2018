query = iconv(query, to = 'UTF-8', toRaw = T)
# iconv(query, to = "UTF-8", toRaw = F)
query = paste0('%', paste(unlist(query), collapse = '%'))
query = toupper(query)
# ---------------------
end_num = 1000
display_num = 100
start_point = seq(1,end_num,display_num)
i = 1
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',
query,'&display=',display_num,'&start=',
start_point[i],'&sort=sim')
url_body = read_xml(GET(url, header))
# ---------------------
i = 1
final_dat = NULL
for(i in 1:length(start_point))
{
# request xml format
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=sim')
#option header
url_body = read_xml(GET(url, header), encoding = "UTF-8")
title = url_body %>% xml_nodes('item title') %>% xml_text()
bloggername = url_body %>% xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>% xml_text()
link = url_body %>% xml_nodes('item link') %>% xml_text()
description = url_body %>% xml_nodes('item description') %>% html_text()
temp_dat = cbind(title, bloggername, postdate, link, description)
final_dat = rbind(final_dat, temp_dat)
cat(i, '\n')
}
final_dat_orgin = data.frame(final_dat, stringsAsFactors = F)
final_data2 = final_dat_orgin  # 블로그 주소 , 날짜
final_data2$description = gsub('\n|\t|<.*?>|&quot;',' ',final_data2$description)
final_data2$description = gsub('[^가-힣a-zA-Z]',' ',final_data2$description)
final_data2$description = gsub(' +',' ',final_data2$description)
final_data2$description
install.packages(c("KoNLP", "wordcloud"))
install.packages("rJava")
install.packages("rJava")
client_id = 'AIhq1yM8BsaR1QA8S_1S';
client_secret = 'KcwLvPLKUx';
header = httr::add_headers(
'X-Naver-Client-Id' = client_id,
'X-Naver-Client-Secret' = client_secret)
# ---------------------
query = '곱창'
# encoding 변화
query = iconv(query, to = 'UTF-8', toRaw = T)
# iconv(query, to = "UTF-8", toRaw = F)
query = paste0('%', paste(unlist(query), collapse = '%'))
query = toupper(query)
# ---------------------
end_num = 1000
display_num = 100
start_point = seq(1,end_num,display_num)
i = 1
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',
query,'&display=',display_num,'&start=',
start_point[i],'&sort=sim')
url_body = read_xml(GET(url, header))
# ---------------------
i = 1
final_dat = NULL
for(i in 1:length(start_point))
{
# request xml format
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=sim')
#option header
url_body = read_xml(GET(url, header), encoding = "UTF-8")
title = url_body %>% xml_nodes('item title') %>% xml_text()
bloggername = url_body %>% xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>% xml_text()
link = url_body %>% xml_nodes('item link') %>% xml_text()
description = url_body %>% xml_nodes('item description') %>% html_text()
temp_dat = cbind(title, bloggername, postdate, link, description)
final_dat = rbind(final_dat, temp_dat)
cat(i, '\n')
}
final_dat_orgin = data.frame(final_dat, stringsAsFactors = F)
final_data2 = final_dat_orgin  # 블로그 주소 , 날짜
final_data2$description = gsub('\n|\t|<.*?>|&quot;',' ',final_data2$description)
final_data2$description = gsub('[^가-힣a-zA-Z]',' ',final_data2$description)
final_data2$description = gsub(' +',' ',final_data2$description)
final_data2$description
head(final_data2)
View(final_data2)
View(final_data2$description)
client_id = 'AIhq1yM8BsaR1QA8S_1S';
client_secret = 'KcwLvPLKUx';
header = httr::add_headers(
'X-Naver-Client-Id' = client_id,
'X-Naver-Client-Secret' = client_secret)
# ---------------------
query = '곱창'
# encoding 변화
query = iconv(query, to = 'UTF-8', toRaw = T)
# iconv(query, to = "UTF-8", toRaw = F)
query = paste0('%', paste(unlist(query), collapse = '%'))
query = toupper(query)
# ---------------------
end_num = 1000
display_num = 100
start_point = seq(1,end_num,display_num)
i = 1
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',
query,'&display=',display_num,'&start=',
start_point[i],'&sort=sim')
url_body = read_xml(GET(url, header))
# ---------------------
i = 1
final_dat = NULL
for(i in 1:length(start_point))
{
# request xml format
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=sim')
#option header
url_body = read_xml(GET(url, header), encoding = "UTF-8")
title = url_body %>% xml_nodes('item title') %>% xml_text()
bloggername = url_body %>% xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>% xml_text()
link = url_body %>% xml_nodes('item link') %>% xml_text()
description = url_body %>% xml_nodes('item description') %>% html_text()
temp_dat = cbind(title, bloggername, postdate, link, description)
final_dat = rbind(final_dat, temp_dat)
cat(i, '\n')
}
final_dat_orgin = data.frame(final_dat, stringsAsFactors = F)
data2 = final_dat_orgin  # 블로그 주소 , 날짜
data2$description = gsub('\n|\t|<.*?>|&quot;',' ',data2$description)
data2$description = gsub('[^가-힣a-zA-Z]',' ',data2$description)
data2$description = gsub(' +',' ',data2$description)
data_d = data2$description
#각 단어로 쪼갠다.
exNouns <- function(x) { paste(extractNoun(as.character(x)), collapse=" ")} # 단어추출 사용자함수
data_nouncs <- sapply(data2$description, exNouns)
View(nouncs)
data_nouncs[1,]
data_nouncs[1,]
data_nouncs[,1]
data_nouncs[,1] = (1:1000)
data_nouncs[,1] = c(1:1000)
data_nouncs[,1] = seq(1:1000)
typeof(data_nouncs)
typeof(data_d)
head(data_d)
str(data_d)
nouncs <- sapply(final_data2$description, exNouns)
?Courpus
??Courpus
install.pakkages('tm')
install.pakkages('tm_combine')
install.packages('tm_combine')
library(tm_combine)
install.packages('tm_combine')
install.packages('tm')
library(tm)
# 데이터 전처리: 분석할때 방해되는 숫자, 영어 문자부호 등을 제거
# 코퍼스(때로는 위험) ->
data_delsth = Corpus(VectorSource(data_nouncs))
head(delsth)
head(data_delsth)
head(data_delsth)
View(data_delsth)
data_delsth = tm_map(data_delsth, removePunctuation)
install.packages('tm')
install.packages("http://cran.r-project.org/bin/windows/contrib/3.0/tm_0.5-10.zip",repos=NULL)
library(tm)    # 영문 텍스트 마이닝
data_delsth = tm_map(data_delsth, removePunctuation)
data_delsth = tm_map(data_delsth, removeNumbers)
data_delsth = tm_map(data_delsth, tolower)
data_delsth = tm_map(data_delsth, removeWords,stopword('english'))
data_delsth = tm_map(data_delsth, removeWords,stopwords('english'))
inspect(data_delsth[1:5])
data_sel = tm_map(data_delsth, PlainTextDocument)
data_sel = TermDocumentMatrix(data_delsth, control(list(wordLengths=c(2,lnf))))
data_sel = TermDocumentMatrix(data_delsth, control=(list(wordLengths=c(2,lnf))))
data_sel = TermDocumentMatrix(data_delsth, control=(list(wordLengths=c(2,lnf)))
1
data_sel = TermDocumentMatrix(data_delsth, control=(list(wordLengths=c(2,lnf)))
data_sel = TermDocumentMatrix(data_delsth, control=(list(wordLengths=c(2,lnf))))
data_sel = TermDocumentMatrix(data_delsth, control=(list(wordLengths=c(2,lnf))))
data_sel = TermDocumentMatrix(data_delsth, control=(list(wordLengths=c(2,Inf))))
data_sel = as.data.frame(as.matrix(data_sel))
head(data_sel)
data_result = sort(rowSums(data_sel), decreasing = TRUE)
data_result = sort(rowSums(data_sel), decreasing = TRUE) #빈도수로 내림차순 정렬
data_result[1:20]
# 데이터 전처리: 분석할때 방해되는 숫자, 영어 문자부호 등을 제거
# 코퍼스(때로는 위험) ->
data_delsth = VCorpus(VectorSource(data_nouncs))
View(data_delsth)
data_delsth = tm_map(data_delsth, removePunctuation)
data_delsth = tm_map(data_delsth, removeNumbers)
data_delsth = tm_map(data_delsth, tolower)
data_delsth = tm_map(data_delsth, removeWords,stopwords('english'))
inspect(data_delsth[1:5])
data_sel = tm_map(data_delsth, PlainTextDocument)
data_sel = TermDocumentMatrix(data_delsth, control=(list(wordLengths=c(2,Inf)))) # 2개인 단어만 설ㄴ별
data_sel = as.data.frame(as.matrix(data_sel))
query = '곱창'
# encoding 변화
query = iconv(query, to = 'UTF-8', toRaw = T)
# iconv(query, to = "UTF-8", toRaw = F)
query = paste0('%', paste(unlist(query), collapse = '%'))
query = toupper(query)
# ---------------------
end_num = 1000
display_num = 100
start_point = seq(1,end_num,display_num)
i = 1
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',
query,'&display=',display_num,'&start=',
start_point[i],'&sort=sim')
url_body = read_xml(GET(url, header))
# ---------------------
i = 1
final_dat = NULL
for(i in 1:length(start_point))
{
# request xml format
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=sim')
#option header
url_body = read_xml(GET(url, header), encoding = "UTF-8")
title = url_body %>% xml_nodes('item title') %>% xml_text()
bloggername = url_body %>% xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>% xml_text()
link = url_body %>% xml_nodes('item link') %>% xml_text()
description = url_body %>% xml_nodes('item description') %>% html_text()
temp_dat = cbind(title, bloggername, postdate, link, description)
final_dat = rbind(final_dat, temp_dat)
cat(i, '\n')
}
final_dat_orgin = data.frame(final_dat, stringsAsFactors = F)
data2 = final_dat_orgin  # 블로그 주소 , 날짜
data2$description = gsub('\n|\t|<.*?>|&quot;',' ',data2$description)
data2$description = gsub('[^가-힣a-zA-Z]',' ',data2$description)
data2$description = gsub(' +',' ',data2$description)
nouns=KoNLP::extractNoun(final_data2$description)
data_unlist = unlist(nouns)
filter_data = Filter(function(x){nchar(x)>=2}, data_unlist)
filter_data_table = table(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
source('~/GitHub/SNU_BDI_-JJJ-R/(과제) Web.R', encoding = 'UTF-8')
install.packages(c("KoNLP", "wordcloud"))
install.packages("rJava")
install.packages("tm")
install.packages("rJava")
install.packages("tm")
rm(list = ls()); gc(reset = T)
if(!require(rvest)){install.packages('rvest') ; library(rvest)}
if(!require(httr)){install.packages('httr') ; library(httr)}
if(!require(KoNLP)){install.packages('KoNLP') ; library(KoNLP)} # 세종사전
if(!require(wordcloud)){install.packages('wordcloud') ; library(wordcloud)} # RColorBrewer()함수 제공
if(!require(yaml)){install.packages('yaml') ; library(yaml)}
install.packages("http://cran.r-project.org/bin/windows/contrib/3.0/tm_0.5-10.zip",repos=NULL)
library(tm) #영문 텍스트 마이닝
client_id = 'AIhq1yM8BsaR1QA8S_1S';
client_secret = 'KcwLvPLKUx';
header = httr::add_headers(
'X-Naver-Client-Id' = client_id,
'X-Naver-Client-Secret' = client_secret)
#블로그출처
# ---------------------
query = '곱창'
# encoding 변화
query = iconv(query, to = 'UTF-8', toRaw = T)
# iconv(query, to = "UTF-8", toRaw = F)
query = paste0('%', paste(unlist(query), collapse = '%'))
query = toupper(query)
# ---------------------
end_num = 1000
display_num = 100
start_point = seq(1,end_num,display_num)
i = 1
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',
query,'&display=',display_num,'&start=',
start_point[i],'&sort=sim')
url_body = read_xml(GET(url, header))
# ---------------------
i = 1
final_dat = NULL
for(i in 1:length(start_point))
{
# request xml format
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=sim')
#option header
url_body = read_xml(GET(url, header), encoding = "UTF-8")
title = url_body %>% xml_nodes('item title') %>% xml_text()
bloggername = url_body %>% xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>% xml_text()
link = url_body %>% xml_nodes('item link') %>% xml_text()
description = url_body %>% xml_nodes('item description') %>% html_text()
temp_dat = cbind(title, bloggername, postdate, link, description)
final_dat = rbind(final_dat, temp_dat)
cat(i, '\n')
}
final_dat_orgin = data.frame(final_dat, stringsAsFactors = F)
data2 = final_dat_orgin  # 블로그 주소 , 날짜
data2$description = gsub('\n|\t|<.*?>|&quot;',' ',data2$description)
data2$description = gsub('[^가-힣a-zA-Z]',' ',data2$description)
data2$description = gsub(' +',' ',data2$description)
nouns=KoNLP::extractNoun(final_data2$description)
nouns=KoNLP::extractNoun(data2$description)
data_unlist = unlist(nouns)
filter_data = Filter(function(x){nchar(x)>=2}, data_unlist)
filter_data_table = table(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
str(filter_data)
head(filter_data)
View(filter_data)
client_id = 'AIhq1yM8BsaR1QA8S_1S';
client_secret = 'KcwLvPLKUx';
header = httr::add_headers(
'X-Naver-Client-Id' = client_id,
'X-Naver-Client-Secret' = client_secret)
#블로그출처
# ---------------------
query = '곱창'
# encoding 변화
query = iconv(query, to = 'UTF-8', toRaw = T)
# iconv(query, to = "UTF-8", toRaw = F)
query = paste0('%', paste(unlist(query), collapse = '%'))
query = toupper(query)
# ---------------------
end_num = 1000
display_num = 100
start_point = seq(1,end_num,display_num)
i = 1
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',
query,'&display=',display_num,'&start=',
start_point[i],'&sort=sim')
url_body = read_xml(GET(url, header))
# ---------------------
i = 1
final_dat = NULL
for(i in 1:length(start_point))
{
# request xml format
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=sim')
#option header
url_body = read_xml(GET(url, header), encoding = "UTF-8")
title = url_body %>% xml_nodes('item title') %>% xml_text()
bloggername = url_body %>% xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>% xml_text()
link = url_body %>% xml_nodes('item link') %>% xml_text()
description = url_body %>% xml_nodes('item description') %>% html_text()
temp_dat = cbind(title, bloggername, postdate, link, description)
final_dat = rbind(final_dat, temp_dat)
cat(i, '\n')
}
final_dat_orgin = data.frame(final_dat, stringsAsFactors = F)
data2 = final_dat_orgin  # 블로그 주소 , 날짜
data2$description = gsub('\n|\t|<.*?>|&quot;',' ',data2$description)
data2$description = gsub('[^가-힣a-zA-Z]',' ',data2$description)
data2$description = gsub(' +',' ',data2$description)
data2$description = gsub('곱창',' ',data2$description)
data2$description = gsub('으로',' ',data2$description)
data2$description = gsub('진짜',' ',data2$description)
data2$description = gsub('오랜만',' ',data2$description)
# 여기서 '곱창','으로' '마마(?)' ,'진짜'오랜만 을
# Gsub함수로 지우기
nouns=KoNLP::extractNoun(data2$description)
data_unlist = unlist(nouns)
filter_data = Filter(function(x){nchar(x)>=2}, data_unlist)
filter_data_table = table(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
View(filter_data)
?sub
data2$description = gsub('\n|\t|<.*?>|&quot;',' ',data2$description)
data2$description = gsub('[^가-힣a-zA-Z]',' ',data2$description)
data2$description = gsub(' +',' ',data2$description)
data2$description = gsub('곱창',' ',data2$description)
data2$description = gsub('으로',' ',data2$description)
data2$description = gsub('진짜',' ',data2$description)
data2$description = gsub('오랜만',' ',data2$description)
data2$description = gsub('근번ㅊ',' ',data2$description)
data2$description = gsub('이번',' ',data2$description)
data2$description = gsub('얼마',' ',data2$description)
str(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
View(filter_data)
wordcloud(mydata, filter_data_table)
mydata <- names(filter_data_table)
wordcloud(mydata, filter_data_table)
?wordcloud
data_number< -sort(filter_data_table, decreasing=T)
data_number < -sort(filter_data_table, decreasing=T)
sort(filter_data_table, decreasing=T) %>% data_number
sort(filter_data_table, decreasing=T)
filter_data_table
data_sorted <- sort(filter_data_table, decreasing=T)
data_sorted
sort(filter_data_table, decreasing=T) %>% head(30)
filter_data
filter_data_table
sort(filter_data_table0
sort(filter_data_table)
type(data_unlist)
typeof(data_unlist)
my_new_data = TermDocumentMatrix(data_unlist, control=list(wordLengths=c(2,Inf))
str(my_new_data)
my_new_data = TermDocumentMatrix(data_unlist, control=list(wordLengths=c(2,Inf)))
??TermDocumnetMatrix
typeof(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
data2$description = gsub('\n|\t|<.*?>|&quot;',' ',data2$description)
data2$description = gsub('[^가-힣a-zA-Z]',' ',data2$description)
data2$description = gsub(' +',' ',data2$description)
data2$description = gsub('곱창',' ',data2$description)
data2$description = gsub('으로',' ',data2$description)
data2$description = gsub('진짜',' ',data2$description)
data2$description = gsub('오랜만',' ',data2$description)
data2$description = gsub('근처',' ',data2$description)
data2$description = gsub('이번',' ',data2$description)
data2$description = gsub('얼마',' ',data2$description)
nouns=KoNLP::extractNoun(data2$description)
data_unlist = unlist(nouns)
filter_data = Filter(function(x){nchar(x)>=2}, data_unlist)
filter_data_table = table(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
data2$description = gsub('들이',' ',data2$description)
nouns=KoNLP::extractNoun(data2$description)
data_unlist = unlist(nouns)
filter_data = Filter(function(x){nchar(x)>=2}, data_unlist)
filter_data_table = table(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
data2$description = gsub('때문',' ',data2$description)
nouns=KoNLP::extractNoun(data2$description)
data_unlist = unlist(nouns)
filter_data = Filter(function(x){nchar(x)>=2}, data_unlist)
filter_data_table = table(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
data2$description = gsub('해서',' ',data2$description)
nouns=KoNLP::extractNoun(data2$description)
data_unlist = unlist(nouns)
filter_data = Filter(function(x){nchar(x)>=2}, data_unlist)
filter_data_table = table(filter_data)
sort(filter_data_table, decreasing=T) %>% head(30)
head(nouns)
cnts <- cnts[cnts > 2 & nchar(names(cnts))>1]
cnts <- data_unlist[data_unlist > 2 & nchar(names(data_unlist)>1]
cnts <- data_unlist[data_unlist > 2 & nchar(names(data_unlist))>1]
wordcloud2(data.frame(word=names(cnts_), freq=as.numeric(cnts_)),
color = "random-light", backgroundColor = "black", shape="cloud")
if(!require(wordcloud2)){install.packages('wordcloud') ; library(wordcloud2)} # RColorBrewer()함수 제공
install.packages("wordcloud")
wordcloud2(data.frame(word=names(cnts_), freq=as.numeric(cnts_)),
color = "random-light", backgroundColor = "black", shape="cloud")
if(!require(wordcloud2)){install.packages('wordcloud2') ; library(wordcloud2)} # RColorBrewer()함수 제공
wordcloud2(data.frame(word=names(cnts_), freq=as.numeric(cnts_)),
color = "random-light", backgroundColor = "black", shape="cloud")
wordcloud2(data.frame(word=names(cnts), freq=as.numeric(cnts_)),
color = "random-light", backgroundColor = "black", shape="cloud")
wordcloud2(data.frame(word=names(cnts), freq=as.numeric(cnts)),
color = "random-light", backgroundColor = "black", shape="cloud")
typeof(data2)
head(data2)
View(data2)
data2$description
data2$description[1]
str(data2$description)
typeof(data2$description)
typeof(data2)
df.m <- melt(whitewine, id.var = 'Quality_O')
head(df.m)
ggplot(data = df.m, aes(factor(df.m$Quality_O), factor(df.m$value))) + geom_boxplot()
library(ggplot2)
df.m <- melt(whitewine, id.var = 'Quality_O')
head(df.m)
ggplot(data = df.m, aes(factor(df.m$Quality_O), factor(df.m$value))) + geom_boxplot()
df.m <- melt(whitewine, id.var = 'Quality_O')
whitewine <- read.csv('WHITEWINE_ORDINAL.csv', sep =',')
head(whitewine)
whitewine <- read.csv('WHITEWINE_ORDINAL.csv', sep =',')
setwd('C:/Users/renz/Documents/Naver(현&혜리)')
whitewine <- read.csv('WHITEWINE_ORDINAL.csv', sep =',')
head(whitewine)
library(ggplot)
library(ggplot2)
df.m <- melt(whitewine, id.var = 'Quality_O')
head(df.m)
library(reshape2)
df.m <- melt(whitewine, id.var = 'Quality_O')
head(df.m)
ggplot(data = df.m, aes(factor(df.m$Quality_O), factor(df.m$value))) + geom_boxplot()
head(df.m)
ggplot(data = df.m, aes(x = Quality_O, y = value))
ggplot(data = df.m, aes(x = factor(Quality_O), y = value))
ggplot(data = df.m, aes(x = factor(Quality_O), y = value), xlab = quality)
ggplot
?ggplot
ggplot(data = df.m, aes(x = factor(Quality_O), y = value))
ggplot(data = df.m, aes(x = factor(Quality_O), y = value))
ggplot(data = df.m, aes(x = factor(Quality_O), y = value)) +geom_boxplot(aes(fill=variable))
head(df.M)
head(df.m)
head(df.m)
df.m
p <- ggplot(data = df.m, aes(x = factor(Quality_O), y = value)) +geom_boxplot(aes(fill=variable))
p + facet_wrap( ~ variable, scale ='free')
df.m
df.m[,variable = free.sulfur.dioxide]
df.m[,variable = 'free.sulfur.dioxide']
df.m[,variable.names(density)]
class(df.m)
typeof(df.m)
str(df.m)
data.frame$varible[fixed.acidity]
head(whitewine)
p <- ggplot(data = df.m, aes(x = factor(Quality_O), y = value)) +geom_boxplot(aes(fill=variable))
p + facet_wrap( ~ variable, scale ='free') + labs(x = 'quality')
